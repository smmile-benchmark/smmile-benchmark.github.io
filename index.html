<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="SMMILE: The first expert-driven multimodal in-context learning benchmark for medical tasks, developed by an international team of 11 medical experts.">
  <meta property="og:title" content="SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning"/>
  <meta property="og:description" content="First expert-driven multimodal ICL benchmark for medical tasks with 111 problems across 6 specialties and 13 imaging modalities"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <meta property="og:image" content="static/image/smmile_banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="SMMILE: Expert-Driven Medical In-Context Learning Benchmark">
  <meta name="twitter:description" content="First multimodal ICL benchmark for medical tasks with expert-curated problems">
  <meta name="twitter:image" content="static/images/smmile_twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="multimodal, in-context learning, medical AI, benchmark, MLLM, medical imaging, expert-driven">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning</h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Melanie Rieff</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Maya Varma</a><sup>2*</sup>,</span>
                <span class="author-block">
                  <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Ossian Rabow</a><sup>2,3</sup>,</span>
                <span class="author-block">
                  <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Subathra Adithan</a><sup>4</sup>,</span>
                <span class="author-block">
                  <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Julie Kim</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Ken Chang</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="SEVENTH AUTHOR PERSONAL LINK" target="_blank">Hannah Lee</a><sup>5</sup>,</span>
                <span class="author-block">
                  <a href="EIGHTH AUTHOR PERSONAL LINK" target="_blank">Nidhi Rohatgi</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="NINTH AUTHOR PERSONAL LINK" target="_blank">Christian Bluethgen</a><sup>2,6,7</sup>,</span>
                <span class="author-block">
                  <a href="TENTH AUTHOR PERSONAL LINK" target="_blank">Mohamed S. Muneer</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="ELEVENTH AUTHOR PERSONAL LINK" target="_blank">Jean-Benoit Delbrouck</a><sup>2†</sup>,</span>
                <span class="author-block">
                  <a href="TWELFTH AUTHOR PERSONAL LINK" target="_blank">Michael Moor</a><sup>1†</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>ETH Zurich</span>
              <span class="author-block"><sup>2</sup>Stanford University</span>
              <span class="author-block"><sup>3</sup>Lund University</span><br>
              <span class="author-block"><sup>4</sup>Jawaharlal Institute of Postgraduate Medical Education and Research</span>
              <span class="author-block"><sup>5</sup>UCSF</span><br>
              <span class="author-block"><sup>6</sup>University of Zurich</span>
              <span class="author-block"><sup>7</sup>University Hospital Zurich</span><br>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution <sup>†</sup>Co-senior authors</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                   <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Supplementary PDF link -->
              <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span>

            <!-- Github link -->
            <span class="link-block">
              <a href="https://github.com/YOUR REPO HERE" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
          </span>

          <!-- HuggingFace Dataset link -->
          <span class="link-block">
            <a href="https://huggingface.co/smmile" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fas fa-database"></i>
            </span>
            <span>Dataset</span>
          </a>
        </span>

          <!-- ArXiv abstract Link -->
          <span class="link-block">
            <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span>
      </div>
    </div>
  </div>
</div>
</div>
</div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
<div class="container is-max-desktop">
  <div class="hero-body">
    <video poster="" id="tree" autoplay controls muted loop height="100%">
      <!-- Your video here -->
      <source src="static/videos/banner_video.mp4"
      type="video/mp4">
    </video>
    <h2 class="subtitle has-text-centered">
      Overview of the SMMILE benchmark. We curate an expert-annotated dataset consisting of multimodal queries paired with two or more task-specific in-context examples to test the ability of MLLMs to perform multimodal in-context learning in the medical domain.
    </h2>
  </div>
</div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
<div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified">
        <p>
          Multimodal in-context learning (ICL) remains underexplored despite holding profound potential for specialized application domains such as medicine. Clinicians routinely encounter diverse, specialized tasks requiring adaptation from limited examples, such as drawing insights from a few relevant prior cases or considering a constrained set of differential diagnoses. While multimodal large language models (MLLMs) have shown impressive advances in medical visual question answering (VQA) or multi-turn chatting, their ability to learn multimodal tasks from context is largely unknown. In this work, we introduce the Stanford Multimodal Medical In-context Learning benchmark (SMMILE), the first expert-driven multimodal ICL benchmark designed for medical tasks. A team of 11 medical experts contributed problems, with each problem including (1) a multimodal query to be posed to a MLLM and (2) multimodal in-context examples designed to serve as demonstrations of the task at hand. The final SMMILE dataset encompasses 111 problems (with 517 question-image-answer triplets) covering 6 medical specialties and 13 imaging modalities. We also introduce a large-scale variant called SMMILE++ consisting of 1038 problems. Results from benchmarking 15 MLLMs on SMMILE and SMMILE++ demonstrate that most MLLMs gain little from multimodal in-context learning on medical tasks; for instance, in open-ended evaluations, ICL contributes to an average performance improvement over zero-shot evaluations of only 6.1 points on SMMILE and 7.3 points on SMMILE++. Further analysis reveals the importance of selecting relevant in-context examples: including just one noisy or irrelevant example can reduce performance by up to 8 points. We also identify a recency bias in evaluated MLLMs, where placing the most relevant example last boosts accuracy by up to 71 points. SMMILE thus highlights critical limitations and biases in current MLLMs when learning multimodal medical tasks from context.
        </p>
      </div>
    </div>
  </div>
</div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small">
<div class="hero-body">
  <div class="container">
    <div id="results-carousel" class="carousel results-carousel">
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/smmile_overview.jpg" alt="SMMILE benchmark overview"/>
      <h2 class="subtitle has-text-centered">
        Expert-driven multimodal in-context learning problems across 6 medical specialties.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/dataset_stats.jpg" alt="Dataset statistics"/>
      <h2 class="subtitle has-text-centered">
        Comprehensive analysis of 111 problems covering diverse medical imaging modalities.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/performance_results.jpg" alt="Performance results"/>
      <h2 class="subtitle has-text-centered">
       Evaluation results showing limited ICL benefits across 15 state-of-the-art MLLMs.
     </h2>
   </div>
   <div class="item">
    <!-- Your image here -->
    <img src="static/images/bias_analysis.jpg" alt="Bias analysis"/>
    <h2 class="subtitle has-text-centered">
      Analysis revealing recency bias and importance of example quality in MLLMs.
    </h2>
  </div>
</div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Youtube video -->
<section class="hero is-small is-light">
<div class="hero-body">
  <div class="container">
    <!-- Paper video. -->
    <h2 class="title is-3">Video Presentation</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <div class="publication-video">
          <!-- Youtube embed code here -->
          <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</div>
</section>
<!-- End youtube video -->

<!-- Video carousel -->
<section class="hero is-small">
<div class="hero-body">
  <div class="container">
    <h2 class="title is-3">Methodology Overview</h2>
    <div id="results-carousel" class="carousel results-carousel">
      <div class="item item-video1">
        <video poster="" id="video1" autoplay controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="static/videos/expert_curation.mp4"
          type="video/mp4">
        </video>
      </div>
      <div class="item item-video2">
        <video poster="" id="video2" autoplay controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="static/videos/evaluation_framework.mp4"
          type="video/mp4">
        </video>
      </div>
      <div class="item item-video3">
        <video poster="" id="video3" autoplay controls muted loop height="100%">\
          <!-- Your video file here -->
          <source src="static/videos/results_analysis.mp4"
          type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</div>
</section>
<!-- End video carousel -->

<!-- Paper poster -->
<section class="hero is-small is-light">
<div class="hero-body">
  <div class="container">
    <h2 class="title">Poster</h2>

    <iframe  src="static/pdfs/smmile_poster.pdf" width="100%" height="550">
        </iframe>

    </div>
  </div>
</section>
<!--End paper poster -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{rieff2024smmile,
  title={SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning},
  author={Rieff, Melanie and Varma, Maya and Rabow, Ossian and Adithan, Subathra and Kim, Julie and Chang, Ken and Lee, Hannah and Rohatgi, Nidhi and Bluethgen, Christian and Muneer, Mohamed S. and Delbrouck, Jean-Benoit and Moor, Michael},
  journal={arXiv preprint},
  year={2024}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
<div class="container">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">

        <p>
          This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>

      </div>
    </div>
  </div>
</div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>
</html>